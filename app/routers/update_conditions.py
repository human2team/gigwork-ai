from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
from openai import OpenAI
import json

router = APIRouter()


class LLMClient:
    """
    OpenAI LLM í˜¸ì¶œìš© ì•„ì£¼ ì–‡ì€ ë˜í¼.
    - response_format=json_object ë¡œ ê°•ì œ
    - JSON ë¬¸ìì—´ì„ íŒŒì‹±í•´ dict ë¡œ ë°˜í™˜
    """

    def __init__(self):
        # OPENAI_API_KEY ëŠ” í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
        self.client = OpenAI()

    def chat_json(self, *, messages: List[Dict[str, str]], model: str = "gpt-5-mini") -> Dict[str, Any]:
        try:
            completion = self.client.chat.completions.create(
                model=model,
                messages=messages,
                response_format={"type": "json_object"},
            )
        except Exception as e:
            raise RuntimeError(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")

        content = completion.choices[0].message.content
        if not content:
            raise RuntimeError("LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

        # content ëŠ” JSON ë¬¸ìì—´ì´ë¯€ë¡œ íŒŒì‹±í•´ì„œ dict ë¡œ ë°˜í™˜
        try:
            return json.loads(content)
        except json.JSONDecodeError as e:
            raise RuntimeError(f"LLMê°€ ìœ íš¨í•œ JSON ì„ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}\nì›ë³¸: {content}")


llm = LLMClient()


class ConditionUpdateRequest(BaseModel):
    history: List[Dict[str, Any]]
    user_input: str
    conditions: Dict[str, Any]


class ConditionUpdateResponse(BaseModel):
    updated_conditions: Dict[str, Any]
    llm_response: str
    missing_fields: Optional[List[str]] = None
    errors: Optional[List[str]] = None


@router.post("/update_conditions", response_model=ConditionUpdateResponse)
def update_conditions(request: ConditionUpdateRequest) -> ConditionUpdateResponse:
    system_prompt = """
ë„ˆëŠ” ë‹¨ê¸° ì•Œë°” ì¡°ê±´ ìˆ˜ì§‘ ì±—ë´‡ì´ë‹¤. ê°„ê²°í•˜ê³  ì •ì¤‘í•˜ê²Œ ì‘ë‹µí•œë‹¤. ì‚¬ìš©ìì˜ ì•Œë°” ì¡°ê±´ì„ ìˆ˜ì§‘í•˜ë©´ì„œ ì‚¬ìš©ìì˜ ì…ë ¥ì— ëŒ€í•œ ìì—°ìŠ¤ëŸ¬ìš´ ì‘ë‹µì„ ìƒì„±í•œë‹¤.
ëŒ€í™”ê°€ ì•Œë°” ì¡°ê±´ ìˆ˜ì§‘ê³¼ ê´€ë ¨ì´ ì—†ìœ¼ë©´, ì •ì¤‘í•˜ê²Œ ì•Œë°” ì¡°ê±´ì— ëŒ€í•´ ë¬¼ì–´ë´ë¼.

ëª©ì 
- ì‚¬ìš©ìì˜ ì…ë ¥ê³¼ ê¸°ì¡´ ì¡°ê±´ì„ ì°¸ê³ í•˜ì—¬ ìµœì¢… ì—…ë°ì´íŠ¸ëœ conditionì„ ìƒì„±í•œë‹¤.
- ìì—°ì–´ ì‘ë‹µì€ llm_responseì— ë„£ê³ , JSON ì™¸ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆë¼.

ë°˜ë“œì‹œ ì•„ë˜ JSON êµ¬ì¡°ë§Œ ë°˜í™˜í•˜ë¼. í‚¤ ì´ë¦„ ë³€ê²½ ê¸ˆì§€.
{
  "updated_conditions": {
        "regions": "ê·¼ë¬´í•˜ê³  ì‹¶ì€ ì§€ì—­ (ì˜ˆ: ê°•ë‚¨êµ¬, ì†¡íŒŒêµ¬). ì—¬ëŸ¬ ê°œ ê°€ëŠ¥.",
        "categories": "ì•Œë°” ì—…ì¢…ì´ë‚˜ ì§ë¬´ (ì˜ˆ: ì¹´í˜, ì£¼ë°©ë³´ì¡°, íƒë°°). ì—¬ëŸ¬ ê°œ ê°€ëŠ¥.",
        "dates": "ê·¼ë¬´ ê°€ëŠ¥í•œ ë‚ ì§œ ë°°ì—´ (ì˜ˆ: 2025-01-10). ì—¬ëŸ¬ ê°œ ê°€ëŠ¥.",
        "start_time": "ê·¼ë¬´ ì‹œì‘ ì‹œê°„ (ì˜ˆ: 09:00).",
        "end_time": "ê·¼ë¬´ ì¢…ë£Œ ì‹œê°„ (ì˜ˆ: 18:00).",
        "wage_min": "í¬ë§í•˜ëŠ” ìµœì†Œ ì‹œê¸‰. ìˆ«ìê°’.",
        "gender": "ì„±ë³„ ì œí•œì´ ìˆëŠ” ê²½ìš° (M,F,N). ëŒ€ë¶€ë¶„ null.",
        "age": "ë‚˜ì´ ë˜ëŠ” ì—°ë ¹ëŒ€ (ì˜ˆ: 25, 20ëŒ€).",
        "job_text": "í•˜ê³  ì‹¶ì€ ì¼ ë˜ëŠ” í¬ë§í˜•íƒœì— ëŒ€í•œ ìì—°ì–´ ì„¤ëª….",
        "person_text": "ë³¸ì¸ì˜ ì„±ê²©, íŠ¹ì„±, ê²½í—˜ ë“± ìê¸° ì†Œê°œ ë¬¸ì¥."
    },
  "llm_response": "...",
}

ì„¤ëª… ë¬¸ì¥ í¬í•¨ ê¸ˆì§€. JSONë§Œ ë°˜í™˜.
"""

    user_prompt = f"""
[ëŒ€í™” íˆìŠ¤í† ë¦¬]
{json.dumps(request.history, ensure_ascii=False, indent=2)}

[ê¸°ì¡´ Conditions]
{json.dumps(request.conditions, ensure_ascii=False, indent=2)}

[ì‚¬ìš©ì ì…ë ¥]
{request.user_input}
"""

    try:
        result = llm.chat_json(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt},
            ],
            model="gpt-5-mini",
        )
    except RuntimeError as e:
        # LLM í˜¸ì¶œ/íŒŒì‹± ì‹¤íŒ¨ ì‹œ HTTP 500
        raise HTTPException(status_code=500, detail=str(e))

    print("\nğŸ” LLM RAW RESULT:\n", result, "\n")

    # LLM ì´ ë°˜í™˜í•œ JSONì—ì„œ í•„ë“œ êº¼ë‚´ê¸°
    updated_conditions = result.get("updated_conditions", {}) or {}
    llm_response_text = result.get("llm_response", "")

    # missing_fields ëŠ” ê°„ë‹¨íˆ ê°’ì´ ë¹„ì–´ìˆëŠ” í‚¤ë“¤ë¡œ êµ¬ì„± (í•„ìš” ì—†ìœ¼ë©´ ì´ ë¶€ë¶„ ì‚­ì œí•´ë„ ë¨)
    expected_keys = [
        "regions",
        "categories",
        "dates",
        "start_time",
        "end_time",
        "wage_min",
        "gender",
        "age",
        "job_text",
        "person_text",
    ]
    missing_fields = [
        key
        for key in expected_keys
        if key not in updated_conditions
        or updated_conditions.get(key) in (None, "", [], {})
    ]

    return ConditionUpdateResponse(
        updated_conditions=updated_conditions,
        llm_response=llm_response_text,
        missing_fields=missing_fields or None,
        errors=None,
    )
